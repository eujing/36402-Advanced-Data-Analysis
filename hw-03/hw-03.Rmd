---
title: "36-402 Homework 3"
author:
- Eu Jing Chua
- eujingc
date: "February 4, 2019"
output:
  pdf_document: default
header-includes:
    - \usepackage{enumerate}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

\newcommand{\est}[1]{\hat{#1}}
\newcommand{\betah}[1]{\est{\beta_{#1}}}
\newcommand{\avg}[1]{\overline{#1}}
\newcommand{\E}[1]{\mathbb{E} \left[ #1 \right]}
\newcommand{\Var}[1]{\text{Var} \left[ #1 \right]}
\newcommand{\Cov}[1]{\text{Cov} \left[ #1 \right]}
\newcommand{\X}{\mathbb{X}}
\newcommand{\sumTo}[1]{\sum^{#1}_{i=1}}
\newcommand{\sumjTo}[1]{\sum^{#1}_{j=1}}
\newcommand{\matr}[1]{\mathbf{#1}}

```{r}
library(knitr)
```

```{r}
stocks <- read.csv("http://www.stat.cmu.edu/~cshalizi/uADA/19/hw/03/stock_history.csv")
```

# Question 1

**Q1 a)**

```{r}
stocks$MAPE <- stocks$Price / stocks$Earnings_10MA_back
kable(as.array(summary(stocks$MAPE)), digits = 3,
      caption = "Summary of `MAPE`")
```

There are exactly 120 NAs as the column `Earnings_10MA_back` has exactly 120 NAs too.

**Q1 b)**

```{r}
lm.fit <- lm(Return_10_fwd ~ MAPE, data = stocks)
kable(coef(summary(lm.fit)), digits = 3,
      caption = "Coefficients of linear model")
```

**Q1 c)**

```{r}
# Taken from textbook chapter 3 page 77
cv.lm <- function(data, formulae, nfolds = 5) {
    data <- na.omit(data)
    formulae <- sapply(formulae, as.formula)
    n <- nrow(data)
    fold.labels <- sample(rep(1:nfolds, length.out = n))
    mses <- matrix(NA, nrow = nfolds, ncol = length(formulae))
    colnames <- as.character(formulae)
    for (fold in 1:nfolds) {
        test.rows <- which(fold.labels == fold)
        train <- data[-test.rows, ]
        test <- data[test.rows, ]
        for (form in 1:length(formulae)) {
            current.model <- lm(formula = formulae[[form]], data = train)
            predictions <- predict(current.model, newdata = test)
            test.responses <- eval(formulae[[form]][[2]], envir = test)
            test.errors <- test.responses - predictions
            mses[fold, form] <- mean(test.errors^2)
        }
    }
    return(colMeans(mses))
}

lm.fit.mse <- cv.lm(stocks, c("Return_10_fwd ~ MAPE"), nfolds = 5)
```
```{r}
kable(lm.fit.mse, digits = 5, caption = "MSE of linear model (5-fold CV)")
```

# Question 2

**Q2 a)**

\begin{align}
Y &= X + \epsilon_t, \hspace{0.05in} \text{where} \\
Y &= R_t \\
X &= \frac{1}{M_t} \\
\epsilon_t &\hspace{0.05in} \text{is the irreducible noise}
\end{align}

In the form of this basic linear regression model, we can see that there is a fixed slope of 1 and fixed intercept of 0.

**Q2 b)**

```{r}
insample.mse <- with(stocks, mean((Return_10_fwd - 1/MAPE)^2, na.rm = TRUE))
kable(insample.mse, digits = 5, caption = "In-sample MSE")
```

**Q2 c)**

In this model, the slope and intercept are fixed. This means that our fixed parameters are not a function of the finite data sample we have seen. Thus, our model will perform the same regardless of where the data is from, whether in-sample or out-of-sample.

**Q2 d)**

```{r}
resids <- with(na.omit(stocks), Return_10_fwd - 1/MAPE)
qqnorm(resids)
qqline(resids)
```

**Q2 e)**

The residuals look roughly Gaussian, but it seems that they have thinner tails than what would have been expected if the distribution were Gaussian.

# Question 3

**Q3 a)**

```{r}
lm.fit.2 <- lm(Return_10_fwd ~ I(1/MAPE), data = stocks)
kable(coef(summary(lm.fit.2))[2, ], digits = 3, col.names = "$\\hat{\\beta}_1$",
      caption = "Slope of generalized basic model")
```

**Q3 b)**

```{r}
lm.fit.2.mse <- cv.lm(stocks, c("Return_10_fwd ~ I(1/MAPE)"), nfolds = 5)
kable(lm.fit.2.mse, digits = 5, caption = "MSE of generalized basic model (5-fold CV)")
```

This generalized basic model has a lower estimated MSE than both the first model and the basic model.

# Question 4

**Q4 a)**

```{r}
kable(coef(summary(lm.fit)), digits = 3,
      caption = "Coefficients of linear model")
```

Since the coefficient of `MAPE` has a p-value very close to 0, it is statistically significant.

**Q4 b)**

```{r}
kable(coef(summary(lm.fit.2)), digits = 3,
      caption = "Coefficients of generalized basic model")
```

Since the coefficient of `1/MAPE` has a p-value very close to 0, it is statistically significant.

**Q4 c)**

```{r}
lm.fit.3 <- lm(Return_10_fwd ~ MAPE + I(1/MAPE), data = stocks)
kable(coef(summary(lm.fit.3)), digits = 3,
      caption = "Coefficients of combined linear models")
```

Both `MAPE` and `1/MAPE` have coefficients that have p-values very close to 0, so both coefficients are statistically significant.

**Q4 d)**

```{r}
lm.fit.4 <- lm(Return_10_fwd ~ MAPE + I(1/MAPE) + I(MAPE^2), data = stocks)
kable(coef(summary(lm.fit.4)), digits = 3,
      caption = "Coefficients of MAPE, 1/MAPE and MAPE^2")
```

The only coefficient that is statistically significant in this model is `1/MAPE`, with a p-value very close to 0.


**Q4 e)**

As we start including more forms of `MAPE` in our linear models, we introduce more correlation between each term in ourgression. This tends to affect the significance of each variable, where higher correlation results in less statistically significant coefficients.

Thus, significance testing is not a viable way of selecting variables for a model as the significance of a single variable in the model is affected by factors such as correlation with other variables, variance of the variable and sample size, all of which have nothing to do with how well the variable can help in predicting the response.

# Question 5

**Q5 a)**

We can conduct a $\alpha$-level significance test for the following hypothesis:

\begin{align}
H_0: \beta_0 = 0 \hspace{0.05in} \text{and} \hspace{0.05in} \beta_1 = 1 \\
H_a: \beta_0 \ne 0 \hspace{0.05in} \text{or} \hspace{0.05in} \beta_1 \ne 1
\end{align}

Since this is essentially testing 2 null hypothesis, we apply the Bonferroni method and instead conduct a $\frac{\alpha}{2}$-level significance test for each of the individual hypothesis, i.e.

\begin{align}
H_0: \beta_1 = 1 \\
H_a: \beta_1 \ne 1
\end{align}

and

\begin{align}
H_0: \beta_0 = 0 \\
H_a: \beta_0 \ne 0
\end{align}

In each test, we can use a $t$-test to conduct the significance testing. Testing that the original null hypothesis holds will be a form of testing whether the basic model is right.

**Q5 b)**

The significance tests that R carries out on the slopes $\beta_i$ assume that the residuals are normally distributed so that the t-score test statistic will have a t-distribution. However, now we see that the residuals in fact are not normally distributed, hence the calculated t-score does not actually have the t-distribution that R is assuming. Hence, the p-values and significance tests will not be accurate.


**Q5 c)**

```{r warning = FALSE}
library(MASS)

resids.t.dist <- fitdistr(resids, "t")
results <- matrix(nrow = 2, ncol = 3)
results[1, ] <- resids.t.dist$estimate
results[2, ] <- resids.t.dist$sd
colnames(results) <- c("m", "s", "df")
rownames(results) <- c("Estimate", "Standard Error")
kable(results, digits = 3, caption = "Parameters of fitted t-distribution")

hist(resids, freq = FALSE, xlab = "Residuals",
     main = "Distribution of residuals")

# From 31 Jan In-class examples
dt.fitted <- function(x,fitted.t) {
  m <- fitted.t$estimate["m"]
  s <- fitted.t$estimate["s"]
  df <- fitted.t$estimate["df"]
  return((1/s)*dt((x-m)/s,df=df)) # why the (1/s) factor out front?
}

curve(dt.fitted(x, resids.t.dist), add = TRUE, col = "red")
```

**Q5 d)**

By analysing the residuals from the basic model and fitting a t-distribution to the residuals, it can be seen that a t-distribution with the parameters above fits the distribution well, especially when plotting the density of the fitted t-distribution against the actual residuals. This matches the observation from how in the normal Q-Q plot, the residuals are observed to have a lighter tail than the normal distribution.

# Question 6

**Q6 a)**

```{r echo = TRUE}
# Simulates the basic model that R_t = 1/M_t + noise,
# where the noise is t-distributed with params from the input.
# Arguments:
#   MAPE: Vector of M_t
#   t.params: Named vector with m, s, and df representing the mean,
#             sample standard deviation, and degrees of freedom of 
#             the t-distribution of the noise
# Returns:
#   Dataframe with a MAPE column and a predicted Return_10_fwd using
#   the basic model above
sim.basic.model <- function(MAPE, t.params) {
    n <- length(MAPE)
    m <- t.params["m"]
    s <- t.params["s"]
    df <- t.params["df"]

    # Generate noise from the input
    noise <- rt(n, df) * s + m

    results <- data.frame(
        MAPE = MAPE,
        Return_10_fwd = 1/MAPE + noise)

    return(results)
}
```

**Q6 b)**

```{r echo = TRUE}
# Runs a linear regression of R_t against 1/M_t, or Return_10_fwd
# against 1/MAPE and returns the slope
# Arguments:
#   data: data frame with Return_10_fwd and MAPE columns
# Returns:
#   slope: Coefficient of the 1/MAPE term in the linear regression
sim.get.slope <- function(data) {
    lm.fit <- lm(Return_10_fwd ~ I(1/MAPE), data = data)
    return(coef(lm.fit)[2])
}
```

**Q6 c)**

```{r cache = TRUE}
sim.results <- replicate(1000, sim.get.slope(sim.basic.model(stocks$MAPE, resids.t.dist$estimate)))
prop <- sum(abs(sim.results - 1) >= abs(coef(lm.fit.2)[2] - 1)) / length(sim.results)
```

```{r}
kable(prop, col.names = "$P(\\mid\\tilde{\\beta}_1 - 1\\mid \\ge \\mid\\hat{\\beta}_1 - 1\\mid)$")
```

**Q6 d)**

\begin{align}
H_0: &\beta_1 = 1 \\
H_a: &\beta_1 \ne 1, \hspace{0.05in} \text{where the test statistic is as follows:} \\
t_{score} &= \frac{|\tilde{\beta}_1 - 1|}{SE_{\tilde{\beta}_1}} \sim T_{df}, \hspace{0.05in} \text{where $df$ is obtained by fitting a t-distribution to the residuals}
\end{align}

The p-value of this test is then `r signif(prop, 3)`, so there is insufficient evidence to reject the null hypothesis. Thus, we conclude at 0.05 significance that the slope is exactly 1.0.

# Question 7

```{r}
library(np)
options(np.messages = FALSE)
```

```{r cache = TRUE}
npreg.fit <- npreg(Return_10_fwd ~ MAPE, data = stocks)
```
```{r}
kable(npreg.fit$bw, digits = 5, col.names = "Bandwidth")
kable(npreg.fit$bws$fval, digits = 5, col.names = "CV MSE")
```

The kernel regression model has a lower CV MSE, and hence better predictive accuracy, in comparison to the other models considered so far.

# Question 8

```{r}
# Q8 a)
plot(Return_10_fwd ~ MAPE, data = stocks,
     ylab = "Returns", cex = 0.5, col = "darkgrey",
     main = "Plot of Returns against MAPE")

# Q8 b)
curve(1/x, add = TRUE)

# Q8 c)
abline(lm.fit, col = "red")
curve(coef(lm.fit.2)[1] + coef(lm.fit.2)[2] / x, add = TRUE, col = "blue")

# Q8 d)
cleaned.stocks <- na.omit(stocks)
MAPE.sorted.idx <- order(cleaned.stocks$MAPE)
lines(cleaned.stocks$MAPE[MAPE.sorted.idx], fitted(npreg.fit)[MAPE.sorted.idx],
      col = "purple")

legend("topright", legend = c("Basic Model", "Linear Reg. with MAPE", "Linear Reg. with 1/MAPE", "Kernel Reg."),
       col = c("black", "red", "blue", "purple"), lty = 1)
```

The kernel regression seems to most resemble the functions of `1/MAPE`. It seems to model the overall decaying pattern of the data, but also has finer variations than the `1/MAPE` functions.

# Question 9

**Q9 a)**

```{r echo = TRUE}
# Runs a kernel regression of Return_10_fwd against MAPE and returns the fitted values
# Arguments:
#   data: Data frame with columns Return_10_fwd and MAPE
# Returns:
#   Vector of fitted values from the kernel regression
kernel.smooth <- function(data) {
    npreg.fit <- npreg(Return_10_fwd ~ MAPE, data = data)
    return(fitted(npreg.fit))
}
```

**Q9 b)**

```{r cache = TRUE}
kernel.fits <- replicate(100, kernel.smooth(sim.basic.model(stocks$MAPE, resids.t.dist$estimate)))
```
```{r}
plot(Return_10_fwd ~ MAPE, data = stocks,
     ylab = "Returns", cex = 0.5, col = "darkgrey",
     main = "Plot of Returns against MAPE")
matplot(cleaned.stocks$MAPE[MAPE.sorted.idx], kernel.fits[MAPE.sorted.idx, ], add = TRUE, lty = 1, col = "red", type = "l", lwd = 0.3)
curve(1/x, add = TRUE)
lines(cleaned.stocks$MAPE[MAPE.sorted.idx], fitted(npreg.fit)[MAPE.sorted.idx],
      col = "blue")
legend("topright", legend = c("Basic model", "Kernel Reg. from Simulations", "Kernel Reg. from Data"),
       col = c("black", "red", "blue"), lwd = c(1, 0.3, 1))
```

The kernel regressions from the data and the simulations do differ, in that the ones from the data are all quite smooth for values of `MAPE` below 30, tracking the function of the basic model quite well, before increasing in variability for values above 30. However, the kernel regression for the actual data is not as smooth throughout, and is consistently lower than most of the regressions of simulations for values around above `MAPE` of 35.

**Q9 c)**

This is a sign that the basic model might not be an accurate model of the underlying process. When running the simulations to produce new data that hopefully looks like the real data, we run the same regressions on both the synthetic data and real data, and then realize that the regressions are not so similar. This implies that the real data does not look like a run of the simulation assuming the basic model, hence the basic model might not be accurate in modelling the actual process.

# Question 10

The results from Q3 b), Q6 d) seem to indicate that the expected returns are roughly inversely proportional to MAPE, as the general estimate of $\hat{R_t} = \hat{\beta}_0 + \hat{\beta}_1 \frac{1}{M_t}$ has better prediction accuracy than the basic model, from the MSEs of their 5-fold cross-validations. However, the results from Q9 c) also shows that the data generated from the basic model where expected returns are exactly inversely proportional to MAPE is not really similar to the real data collected. Hence, there does seem to be a rough inversely proportional relationship, but it is not exact in nature.
